## [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

### Abstract
Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations. 

### 1. Introduction 
Machine learning systems now excel (in expectation) at tasks they are trained for by using a combination of large datasets, high-capacity models, and supervised learning (Krizhevsky et al., 2012) (Sutskever et al., 2014) (Amodei et al., 2016). Yet these systems are brittle and sensitive to slight changes in the data distribution (Recht et al., 2018) and task specification (Kirkpatrick et al., 2017). Current systems are better characterized as narrow experts rather than competent generalists. We would like to move towards more general systems which can perform many tasks – eventually without the need to manually create and label a training dataset for each one. 

The dominant approach to creating ML systems is to collect a dataset of training examples demonstrating correct behavior for a desired task, train a system to imitate these behaviors, and then test its performance on independent and identically distributed (IID) held-out examples. This has served well to make progress on narrow experts. But the often erratic behavior of captioning models (Lake et al., 2017), reading comprehension systems (Jia & Liang, 2017), and image classifiers (Alcorn et al., 2018) on the diversity and variety of possible inputs highlights some of the shortcomings of this approach.

## Translation

### Аннотация
Задачи обработки естественного языка, такие как ответы на вопросы, машинный перевод, понимание прочитанного и обобщение, обычно решаются с помощью контролируемого обучения на наборах данных, специфичных для конкретной задачи. Мы демонстрируем, что языковые модели начинают обучаться этим задачам без явного контроля при обучении на новом наборе данных из миллионов веб-страниц под названием WebText. При задании документа и вопросов ответы, сгенерированные языковой моделью, достигают 55 F1 на наборе данных CoQA, что соответствует или превосходит производительность 3 из 4 базовых систем без использования 127 000+ обучающих примеров. Мощность языковой модели очень важна для успешного переноса задач с нулевым результатом, и ее увеличение повышает производительность в логарифмической прогрессии для всех задач. Наша самая большая модель, GPT-2, представляет собой трансформатор с параметрами 1,5 ББ, который достигает лучших результатов на 7 из 8 тестируемых наборов данных для языкового моделирования в режиме «нулевого выстрела», но все еще не справляется с WebText. Образцы из модели отражают эти улучшения и содержат связные абзацы текста. Эти результаты указывают на перспективный путь к созданию систем обработки языка, которые учатся выполнять задачи на основе их естественных демонстраций. 

### 1 Введение
В настоящее время системы машинного обучения превосходят (в ожидании) задачи, которым они обучены, благодаря сочетанию больших наборов данных, высокопроизводительных моделей и контролируемого обучения (Krizhevsky et al., 2012) (Sutskever et al., 2014) (Amodei et al., 2016). Однако эти системы хрупки и чувствительны к незначительным изменениям в распределении данных (Recht et al., 2018) и спецификации задачи (Kirkpatrick et al., 2017). Нынешние системы лучше характеризовать как узких экспертов, а не компетентных универсалов. Мы хотели бы перейти к более общим системам, которые могут выполнять множество задач - в конечном итоге без необходимости вручную создавать и маркировать обучающие наборы данных для каждой из них. 

Доминирующий подход к созданию ML-систем заключается в сборе набора обучающих примеров, демонстрирующих правильное поведение для желаемой задачи, обучении системы имитировать это поведение, а затем проверке ее работы на независимых и идентично распределенных (IID) удерживаемых примерах. Такой подход хорошо помогает добиться прогресса в работе с узкими специалистами. Однако зачастую нестабильное поведение моделей создания субтитров (Lake et al., 2017), систем понимания прочитанного (Jia & Liang, 2017) и классификаторов изображений (Alcorn et al., 2018) на многообразии и разнообразии возможных входных данных подчеркивает некоторые недостатки этого подхода.