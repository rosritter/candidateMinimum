## [ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification](https://arxiv.org/pdf/2005.07143)

### Abstract
Current speaker verification techniques rely on a neural network to extract speaker representations. The successful x-vector architecture is a Time Delay Neural Network (TDNN) that applies statistics pooling to project variable-length utterances into fixed-length speaker characterizing embeddings. In this paper, we propose multiple enhancements to this architecture based on recent trends in the related fields of face verification and computer vision. Firstly, the initial frame layers can be restructured into 1-dimensional Res2Net modules with impactful skip connections. Similarly to SE-ResNet, we introduce Squeeze-andExcitation blocks in these modules to explicitly model channel interdependencies. The SE block expands the temporal context of the frame layer by rescaling the channels according to global properties of the recording. Secondly, neural networks are known to learn hierarchical features, with each layer operating on a different level of complexity. To leverage this complementary information, we aggregate and propagate features of different hierarchical levels. Finally, we improve the statistics pooling module with channel-dependent frame attention. This enables the network to focus on different subsets of frames during each of the channel’s statistics estimation. The proposed ECAPA-TDNN architecture significantly outperforms state-ofthe-art TDNN based systems on the VoxCeleb test sets and the 2019 VoxCeleb Speaker Recognition Challenge.

### 1 Introduction
In recent years, x-vectors [1] and their subsequent improvements [2, 3, 4] have consistently provided state-of-the-art results on the task of speaker verification. Improving upon the original Time Delay Neural Network (TDNN) architecture is an active area of research. Usually, the neural networks are trained on the speaker identification task. After convergence, low dimensional speaker embeddings can be extracted from the bottleneck layer preceding the output layer to characterize the speaker in the input recording. Speaker verification can be accomplished by comparing the two embeddings corresponding with an enrollment and a test recording to accept or reject the hypothesis that both recordings contain the same speaker. A simple cosine distance measurement can be used for this comparison. In addition, a more complicated scoring backend can be trained such as Probabilistic Linear Discriminant Analysis (PLDA) [5]. 

The rising popularity of the x-vector system has resulted in significant architectural improvements and optimized training procedures [6] over the original approach. The topology of the system was improved by incorporating elements of the popular ResNet [7] architecture. Adding residual connections between the frame-level layers has been shown to enhance the embeddings [3, 4]. Additionally, residual connections enable the back-propagation algorithm to converge faster and help avoid the vanishing gradient problem [7].


## Translation

### Аннотация
Современные методы проверки диктора полагаются на нейронную сеть для извлечения представлений диктора. Успешная архитектура x-vector представляет собой нейронную сеть с временной задержкой (TDNN), которая применяет объединение статистики для проецирования высказываний переменной длины в вкрапления, характеризующие диктора, фиксированной длины. В данной работе мы предлагаем несколько усовершенствований этой архитектуры, основанных на последних тенденциях в смежных областях верификации лиц и компьютерного зрения. Во-первых, начальные слои кадров могут быть реструктурированы в одномерные модули Res2Net с влиятельными связями пропусков. Аналогично SE-ResNet, мы вводим блоки Squeeze иExcitation в эти модули для явного моделирования взаимозависимостей каналов. Блок SE расширяет временной контекст слоя кадров, изменяя масштаб каналов в соответствии с глобальными свойствами записи. Во-вторых, известно, что нейронные сети обучаются иерархическим характеристикам, причем каждый слой работает на разном уровне сложности. Чтобы использовать эту дополнительную информацию, мы объединяем и распространяем признаки разных иерархических уровней. Наконец, мы улучшаем модуль объединения статистики с помощью канально-зависимого внимания к кадрам. Это позволяет сети фокусироваться на различных подмножествах кадров во время каждой оценки статистики канала. Предложенная архитектура ECAPA-TDNN значительно превосходит современные системы на основе TDNN на тестовых наборах VoxCeleb и в конкурсе 2019 VoxCeleb Speaker Recognition Challenge.


### 1 Введение
В последние годы x-векторы [1] и их последующие усовершенствования [2, 3, 4] неизменно показывают самые высокие результаты в задаче верификации диктора. Совершенствование оригинальной архитектуры нейронной сети с временной задержкой (TDNN) является активной областью исследований. Обычно нейронные сети обучаются на задаче идентификации диктора. После сходимости из узкого слоя, предшествующего выходному слою, могут быть извлечены низкоразмерные вкрапления диктора, характеризующие диктора во входной записи. Проверка диктора может быть выполнена путем сравнения двух вкраплений, соответствующих записи регистрации и тестовой записи, чтобы принять или отвергнуть гипотезу о том, что обе записи содержат одного и того же диктора. Для такого сравнения можно использовать простое измерение косинусного расстояния. Кроме того, можно обучить более сложный бэкграунд, например, вероятностный линейный дискриминантный анализ (PLDA) [5]. 

Растущая популярность системы x-vector привела к значительным архитектурным улучшениям и оптимизации процедур обучения [6] по сравнению с оригинальным подходом. Топология системы была улучшена за счет включения элементов популярной архитектуры ResNet [7]. Было показано, что добавление остаточных связей между слоями на уровне кадров улучшает вкрапления [3, 4]. Кроме того, остаточные связи позволяют алгоритму обратного распространения сходиться быстрее и помогают избежать проблемы исчезающего градиента [7].